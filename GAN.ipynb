{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source : https://medium.com/geekculture/introduction-to-the-gan-in-pytorch-bba920347b01\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as alt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary classifier that determines whether data points are from the original distribution or the fake (generated) distribution\n",
    "class Discriminator(torch.nn.Module):\n",
    "  def __init__(self, input_dim=2, hidden_dim=28, n_layers=3):\n",
    "    super(Discriminator,self).__init__()\n",
    "\n",
    "    self.input = torch.nn.Sequential( torch.nn.Linear(input_dim, hidden_dim), torch.nn.LeakyReLU() )\n",
    "    self.layers = []\n",
    "    for i in range(n_layers):\n",
    "      self.layers.append( torch.nn.Sequential( torch.nn.Linear(hidden_dim, hidden_dim), torch.nn.LeakyReLU() ) )\n",
    "    \n",
    "    self.layers = torch.nn.ModuleList(self.layers)\n",
    "    self.output = torch.nn.Sequential( torch.nn.Linear(hidden_dim, 1), torch.nn.Sigmoid() )\n",
    "\n",
    "  def forward(self, x):\n",
    "    o = self.input(x)\n",
    "    for layer in self.layers:\n",
    "      o = layer(o)\n",
    "\n",
    "    o = self.output(o)\n",
    "    return o\n",
    "  \n",
    "#Generator, takes in random noise and outputs a fake point\n",
    "class Generator(torch.nn.Module):\n",
    "  def __init__(self, z_dim=1, hidden_dim=28, n_layers=3, out_dim=2):\n",
    "    super(Generator, self).__init__()\n",
    "\n",
    "    self.input = torch.nn.Sequential( torch.nn.Linear(z_dim, hidden_dim), torch.nn.LeakyReLU() )\n",
    "    self.layers = []\n",
    "    for i in range(n_layers):\n",
    "      self.layers.append( torch.nn.Sequential( torch.nn.Linear(hidden_dim, hidden_dim ), torch.nn.LeakyReLU() ) )\n",
    "    \n",
    "    self.layers = torch.nn.ModuleList(self.layers)\n",
    "    self.output = torch.nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    o = self.input(x)\n",
    "    for layer in self.layers:\n",
    "      o = layer(o)\n",
    "\n",
    "    o = self.output(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample n points from [-range/2,range/2] from distribution\n",
    "#dist is a single parameter function\n",
    "def sample_dist(n, r, dist, mode='1d'):\n",
    "  data = []\n",
    "\n",
    "  if mode == '1d':\n",
    "    x = r*(np.random.random_sample((n,))-0.5)\n",
    "    \n",
    "    for i in range(n):\n",
    "          data.append([x[i], dist(x[i])])\n",
    "  elif mode == '2d':\n",
    "    for i in range(n):\n",
    "      #2d dist auto samples from x,y\n",
    "      out = dist()\n",
    "      data.append([out[0], out[1]])\n",
    "\n",
    "  return np.array(data)\n",
    "\n",
    "#sample noise uniformly from -1 to 1, n vectors with dimensionality m\n",
    "#m is the dimension of the latent space\n",
    "def sample_noise(n, m):\n",
    "  return np.random.uniform(-1., 1., size=[n, m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabolic_dist(x):\n",
    "  return x*x\n",
    "\n",
    "def inverse_parabolic_dist(x):\n",
    "  return -(x*x)\n",
    "\n",
    "def gauss_2d(mu=0, sigma=1):\n",
    "    x = random.gauss(mu, sigma)\n",
    "    y = random.gauss(mu, sigma)\n",
    "    return (x, y)\n",
    "\n",
    "def circle():\n",
    "    theta = random.random() * 2 * np.pi\n",
    "    x = np.cos(theta)\n",
    "    y = np.sin(theta)\n",
    "    return (x, y)\n",
    "\n",
    "def square():\n",
    "    r = random.random() * 4\n",
    "    pos = random.random() - 0.5\n",
    "    if r > 3:\n",
    "      return (0.5, pos)\n",
    "    if r > 2:\n",
    "      return (-0.5, pos)\n",
    "    if r > 1:\n",
    "      return (pos, 0.5)\n",
    "    else :\n",
    "      return (pos, -0.5)\n",
    "\n",
    "def heart():\n",
    "    t = random.random() * 2 * np.pi;\n",
    "    x = 16 * np.sin(t) * np.sin(t) * np.sin(t)\n",
    "    y = 13 * np.cos(t) - 5 * np.cos(2 * t) - 2 * np.cos(3 * t) - np.cos(4 * t)\n",
    "    return (x, y)\n",
    "\n",
    "def infinity():\n",
    "    t = (random.random() * 2 * np.pi) - 0.5 * np.pi;\n",
    "    x = np.cos(t)\n",
    "    y = np.cos(t) * np.sin(t)\n",
    "    return (x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gen, disc, optimG, optimD, distribution, criterion, fixed_noise, r=50, z_dim=10, num_epochs=30000, batch_size=32, mode='1d', device='cuda'):\n",
    "  real_label = 1\n",
    "  fake_label = 0\n",
    "\n",
    "  gen_list = []\n",
    "  G_losses = []\n",
    "  D_losses = []\n",
    "  iters = 0\n",
    "\n",
    "  print(\"Training...\")\n",
    "  print(device)\n",
    "  for epoch in range(num_epochs):\n",
    "        #max log(D(x)) + log(1 - D(G(z)))\n",
    "        #train on real points\n",
    "        disc.zero_grad()\n",
    "        \n",
    "        real_points = torch.tensor( sample_dist(n=batch_size, r=r, dist=distribution, mode=mode) ).float()\n",
    "        label = torch.full( (batch_size,), real_label, dtype=torch.float, device=device ).view(-1)\n",
    "\n",
    "        output = disc(real_points).view(-1)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "\n",
    "        #train on fake points\n",
    "        noise = torch.randn(batch_size, z_dim, device=device)\n",
    "        fake_points = gen(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = disc(fake_points.detach()).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        \n",
    "        errD = errD_real + errD_fake\n",
    "\n",
    "        optimizerD.step()\n",
    "\n",
    "        #max log(D(G(z)))\n",
    "        gen.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "\n",
    "        output = disc(fake_points).view(-1)\n",
    "\n",
    "        errG = criterion(output, label)\n",
    "\n",
    "        errG.backward()\n",
    "\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if iters % 50 == 0:\n",
    "            print('[%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
    "                  % (epoch, num_epochs, errD.item(), errG.item()))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).detach().cpu()\n",
    "            gen_list.append(fake)\n",
    "\n",
    "        iters += 1\n",
    "\n",
    "  gen_list = np.array([np.array(x) for x in gen_list])\n",
    "  return gen, disc, G_losses, D_losses, gen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(G_losses, D_losses):\n",
    "  #plot losses\n",
    "  plt.figure()\n",
    "  plt.title('Generator and Discriminator Losses')\n",
    "  plt.plot(range(len(G_losses)), G_losses, color='green')\n",
    "  plt.plot(range(len(D_losses)), D_losses, color='red')\n",
    "\n",
    "def make_anim(gen_list, distribution, r, mode='1d'):\n",
    "\n",
    "  if mode == '1d':\n",
    "    plt.rc('animation', html='jshtml')\n",
    "\n",
    "    def update(i):\n",
    "      ax.set_xlabel('Step: {}'.format(i))\n",
    "      xf = [t[0] for t in gen_list[i]]\n",
    "      yf = [t[1] for t in gen_list[i]]\n",
    "      ax.clear()\n",
    "      ax.set_xlim((-r*2,r*2))\n",
    "      ax.scatter(range(-r,r), reals, color='blue', zorder=30)\n",
    "      ax.scatter(xf, yf, color='red')\n",
    "      ax.set_aspect('equal')\n",
    "\n",
    "      return ax\n",
    "      \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_tight_layout(False)\n",
    "\n",
    "    reals = [distribution(x) for x in range(-r,r)]\n",
    "    anim = alt.FuncAnimation(fig, update, frames=np.arange(0, gen_list.shape[0]), interval=200)\n",
    "\n",
    "    #plot final generated pairs vs real distribution\n",
    "    xf = [t[0] for t in gen_list[gen_list.shape[0]-1]]\n",
    "    yf = [t[1] for t in gen_list[gen_list.shape[0]-1]]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Final Generator Fitting')\n",
    "    plt.scatter(range(-r,r), reals, color='blue')\n",
    "    plt.scatter(xf, yf, color='red', zorder=30)\n",
    "    plt.axis('scaled')\n",
    "\n",
    "\n",
    "\n",
    "  elif mode == '2d':\n",
    "    plt.rc('animation', html='jshtml')\n",
    "\n",
    "    def update(i):\n",
    "      ax.set_xlabel('Step: {}'.format(i))\n",
    "      xf = [t[0] for t in gen_list[i]]\n",
    "      yf = [t[1] for t in gen_list[i]]\n",
    "      ax.clear()\n",
    "      ax.set_xlim((min(xr),max(xr)))\n",
    "      ax.scatter(xr, yr, color='blue')\n",
    "      ax.scatter(xf, yf, color='red', zorder=30)\n",
    "      ax.set_aspect('equal')\n",
    "\n",
    "\n",
    "      return ax\n",
    "      \n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_tight_layout(False)\n",
    "\n",
    "    reals = [distribution() for x in range(r)]\n",
    "    anim = alt.FuncAnimation(fig, update, frames=np.arange(0, gen_list.shape[0]), interval=200)\n",
    "\n",
    "    #plot final generated pairs vs real distribution\n",
    "    xf = [t[0] for t in gen_list[gen_list.shape[0]-1]]\n",
    "    yf = [t[1] for t in gen_list[gen_list.shape[0]-1]]\n",
    "\n",
    "    xr = [t[0] for t in reals]\n",
    "    yr = [t[1] for t in reals]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Final Generator Fitting')\n",
    "    plt.scatter(xr, yr, color='blue')\n",
    "    plt.scatter(xf, yf, color='red', zorder=30)\n",
    "    plt.axis('scaled')\n",
    "\n",
    "\n",
    "  return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train to fit simple function x^2\n",
    "z_dim = 10\n",
    "num_epochs = 30000\n",
    "batch_size = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "generator = Generator(z_dim=z_dim, hidden_dim=28, n_layers=3, out_dim=2).to(device)\n",
    "discriminator = Discriminator(input_dim=2, hidden_dim=28, n_layers=3).to(device)\n",
    "\n",
    "optimizerD = torch.optim.Adam(discriminator.parameters())\n",
    "optimizerG = torch.optim.Adam(generator.parameters())\n",
    "fixed_noise = torch.randn(128, z_dim, device=device)\n",
    "\n",
    "distribution = infinity\n",
    "r = 512 \n",
    "#r = 25\n",
    "mode = '2d'\n",
    "#mode = '1d'\n",
    "\n",
    "generator, discriminator, gloss, dloss, gen_list = train(generator, discriminator, optimizerG, optimizerD, distribution, criterion, fixed_noise, r=50, z_dim=z_dim, num_epochs=num_epochs, batch_size=batch_size, device=device, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(gloss, dloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_anim(gen_list, distribution, r, mode=mode)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b05e84dc0b10ef20cb8dbe56f3e7c0683a2dcd0fff23e9eb10dd12695aad82fc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
